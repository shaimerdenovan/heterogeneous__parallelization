## Описание работы
Лабораторная работа №5 посвящена изучению параллельных структур данных на GPU с использованием технологии CUDA. В работе рассматриваются такие структуры данных, как стек (stack) и очередь (queue), а также их поведение при параллельном доступе со стороны большого количества потоков.
Основное внимание уделяется проблемам синхронизации потоков, использованию атомарных операций и влиянию различных типов памяти CUDA на корректность и производительность программ. В дополнительной части работы реализована очередь с поддержкой нескольких производителей и потребителей (MPMC), а также выполнено сравнение с последовательными реализациями на CPU.

## Среда выполнения
Работа выполнялась в среде Google Colab с включённым GPU, так как у меня на ноутбуке нет видеокарты NVIDIA. Для измерения времени выполнения CUDA-ядер использовались события cudaEvent, что позволяет учитывать только время работы на GPU без учёта копирования данных между CPU и GPU.

## Основная часть работы (lab5.cu)
#### Стек (Stack)
В первой части работы был реализован параллельный стек (LIFO), хранящийся в глобальной памяти GPU. Каждый поток выполняет операции push и pop, при этом для защиты общего счётчика вершины стека используются атомарные операции atomicAdd и atomicSub. Корректность работы проверяется на CPU путём анализа результатов операций pop. Также измеряется время выполнения ядра.

#### Очередь (Queue)
Во второй части реализована простая очередь (FIFO). Для упрощения и корректной работы операции добавления и извлечения элементов выполняются в двух отдельных ядрах:
- enqueue - добавление элементов,
- dequeue - извлечение элементов.
Как и в случае со стеком, используются атомарные операции для защиты общих индексов очереди. После выполнения производится проверка корректности и замер времени.

#### Сравнение производительности
В конце программы выполняется сравнение времени выполнения операций со стеком и очередью. Это позволяет оценить относительную стоимость различных структур данных при параллельном доступе.

## Дополнительные задания (lab5_additional.cu)

#### Оптимизация с использованием разделяемой памяти

Для стека и очереди были реализованы оптимизированные версии операций добавления элементов, в которых используется разделяемая память. В этих версиях уменьшается количество атомарных операций за счёт групповой обработки данных на уровне блока. 
#### Очередь с несколькими производителями и потребителями (MPMC)
В дополнительной части реализована MPMC очередь (multiple producers, multiple consumers), основанная на кольцевом буфере и массиве sequence numbers. Такая очередь позволяет нескольким потокам одновременно добавлять и извлекать элементы без использования глобальных блокировок.
Корректность работы проверяется запуском двух ядер: ядро производителей (producers) и ядро потребителей (consumers).

#### Сравнение с CPU
Для оценки эффективности GPU-реализаций были реализованы последовательные версии стека и очереди на CPU. В конце программы выводится сравнение времени выполнения GPU и CPU версий.

## Вывод

В ходе выполнения лабораторной работы было показано, что параллельная работа со структурами данных требует аккуратной синхронизации потоков. Использование атомарных операций позволяет обеспечить корректность, но может снижать производительность. Применение разделяемой памяти помогает уменьшить количество атомарных операций и ускорить выполнение программ. Также видно, что GPU-реализации значительно выигрывают по производительности по сравнению с последовательными версиями на CPU при большом количестве операций.
## Ответы на контрольные вопросы
1. В чём отличие стека и очереди?
Стек работает по принципу LIFO (последний пришёл первый вышел). Очередь работает по принципу FIFO (первый пришёл первый вышел). В стеке элементы добавляются и извлекаются с одной стороны а в очереди с разных.

2. Какие проблемы возникают при параллельном доступе к данным?
Основные проблемы — это гонки данных (race conditions), когда несколько потоков одновременно изменяют одну и ту же переменную. Это может приводить к потере данных и некорректным результатам. Также возможны проблемы с синхронизацией и непредсказуемым порядком выполнения потоков.

3. Как атомарные операции помогают избежать конфликтов в параллельных структурах данных?
Атомарные операции гарантируют что операция чтения и записи выполняется как единое целое. Это предотвращает одновременное изменение одной и той же переменной несколькими потоками и позволяет безопасно обновлять счётчики и индексы в параллельных структурах данных.

4. Какие типы памяти CUDA используются для хранения данных?
В работе используются глобальная память - основная память для хранения структур данных, разделяемая память - быстрая память внутри блока для оптимизации, локальная память - локальные переменные потоков, и host memory - память CPU для хранения и анализа результатов.

5. Как синхронизация потоков влияет на производительность?
Синхронизация необходима для корректности но она замедляет выполнение программы так как потоки вынуждены ждать друг друга. Избыточная синхронизация снижает параллелизм, поэтому её нужно использовать только там где это действительно необходимо.

6. Почему разделяемая память важна для оптимизации работы параллельных структур данных?
Разделяемая память намного быстрее глобальной. Если данные используются несколькими потоками одного блока, хранение их в разделяемой памяти позволяет уменьшить количество обращений к глобальной памяти и атомарных операций что значительно повышает производительность.
