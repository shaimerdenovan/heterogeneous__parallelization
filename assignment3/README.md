## Описание работы
Assignment 3 посвящён изучению архитектуры GPU и основ оптимизации программ на CUDA. В работе рассматривается, как разные способы работы с памятью и выбор параметров запуска CUDA-ядер влияют на скорость выполнения программ. Все задания были выполнены и протестированы на массиве размером 1 000 000 элементов с использованием GPU Tesla T4 в среде Google Colab.
## Среда выполнения
Работа выполнялась в Google Colab с включённым GPU. Для замера времени использовались события cudaEvent, что позволяет измерять только время работы CUDA-ядра на GPU без учёта копирования данных между CPU и GPU. Для более точных результатов каждое ядро запускалось несколько раз, а время усреднялось.
## Задача 1. Поэлементное умножение массива
В первой задаче была реализована программа для умножения каждого элемента массива на число. Были сделаны две версии:
1. Версия с использованием только глобальной памяти.
2. Версия с использованием разделяемой (shared) памяти.
Результаты показали, что версия с global memory работает немного быстрее, чем версия с shared memory. Это связано с тем, что в данной задаче каждый элемент используется только один раз. Использование shared памяти добавляет лишние операции копирования и синхронизации потоков, поэтому ускорения не происходит.
## Задача 2. Поэлементное сложение двух массивов
Во второй задаче реализовано поэлементное сложение двух массивов. Для исследования производительности были выбраны разные размеры блока потоков: 128, 256 и 512.
Результаты показали, что время выполнения для всех трёх вариантов практически одинаковое. Это объясняется тем, что операция сложения массивов ограничена скоростью работы памяти, а не вычислениями. Поэтому изменение размера блока в разумных пределах не даёт заметного ускорения.
## Задача 3. Коалесцированный и некоалесцированный доступ к памяти
В третьей задаче сравнивались два варианта доступа к глобальной памяти:
- Коалесцированный доступ, когда потоки одного варпа читают соседние элементы массива.
- Некоалесцированный доступ, когда потоки читают данные с большим шагом, из-за чего обращения к памяти становятся разрозненными.
Эксперименты показали, что коалесцированный доступ работает значительно быстрее. Некоалесцированный вариант оказался примерно в несколько раз медленнее, так как GPU приходится выполнять больше операций доступа к памяти.
## Задача 4. Задача 4. Подбор оптимальной конфигурации
В четвёртой задаче для программы по сложению массивов был выполнен подбор параметров запуска CUDA-ядра. Сравнивались неоптимальный размер блока (64 потока) и лучший вариант из протестированных (128 потоков).
Результаты показали небольшое ускорение при использовании оптимального размера блока. Ускорение оказалось не очень большим, так как сама задача простая и ограничена пропускной способностью памяти.
## Вывод
В ходе выполнения работы стало понятно, что для простых поэлементных операций производительность чаще всего ограничена скоростью работы с памятью, а не вычислениями. Использование shared памяти даёт эффект только тогда, когда данные используются несколько раз, иначе она может даже замедлять выполнение. Коалесцированный доступ к глобальной памяти сильно влияет на скорость работы программы и позволяет значительно её ускорить. Также подбор параметров блоков и сетки может дать небольшой прирост производительности даже без изменения алгоритма.
## Ответы на контрольные вопросы
1. Какие основные типы памяти существуют в архитектуре CUDA и чем они отличаются по скорости доступа?

В CUDA есть несколько типов памяти и это регистры, разделяемая память и глобальная память. Регистры и разделяемая память самые быстрые но их мало. Глобальная память самая медленная но в ней можно хранить большие массивы данных.

2. В каких случаях использование разделяемой памяти позволяет ускорить выполнение CUDA-программы?

Разделяемая память полезна тогда когда одни и те же данные используются несколько раз разными потоками одного блока. В таком случае данные можно загрузить из глобальной памяти один раз и потом быстро использовать из shared памяти.

3. Как шаблон доступа к глобальной памяти влияет на производительность GPU-программы?

Если потоки обращаются к памяти подряд (коалесцированный доступ), программа работает быстрее. Если потоки читают данные с большими пропусками, то доступ к памяти становится медленным и программа сильно замедляется.

4. Почему одинаковый алгоритм на GPU может показывать разное время выполнения при разных способах обращения к памяти?

Потому что GPU очень чувствителен к тому как именно происходит доступ к памяти. Даже если вычисления одинаковые, неправильный порядок чтения данных может сильно увеличить время работы.

5. Как размер блока потоков влияет на производительность CUDA-ядра?

Размер блока влияет на то насколько хорошо загружен GPU. Если блок слишком маленький, GPU используется не полностью. Если слишком большой, могут возникнуть ограничения по ресурсам и производительность тоже снизится.

6. Что такое варп и почему важно учитывать его при разработке CUDA-программ?

Варп это группа из 32 потоков которые выполняются одновременно. Важно чтобы потоки внутри варпа выполняли одинаковые инструкции и обращались к памяти эффективно, иначе производительность падает.

7. Какие факторы необходимо учитывать при выборе конфигурации сетки и блоков потоков?

Нужно учитывать размер задачи, ограничения GPU, количество потоков в блоке, использование памяти и характер доступа к данным. Всё это влияет на скорость работы программы.

8. Почему оптимизация CUDA-программы часто начинается с анализа работы с памятью, а не с изменения алгоритма?

Потому что в большинстве CUDA-программ узким местом является память и если улучшить доступ к памяти, можно получить заметное ускорение даже без изменения самого алгоритма.
