## Описание работы
В Assignment 4 были рассмотрены способы ускорения вычислений с использованием GPU (CUDA) и распределённых вычислений с помощью MPI. Работа состоит из четырёх заданий, в которых реализуются последовательные, параллельные, гибридные и распределённые алгоритмы, а также проводится сравнение их производительности.

#### Задание 1
В первом задании была реализована CUDA программа для вычисления суммы элементов массива размером 100 000 с использованием глобальной памяти GPU. Каждый поток суммирует часть массива затем выполняется редукция внутри блока и итоговая сумма добавляется в глобальную переменную с помощью atomicAdd. Для сравнения реализована последовательная версия на CPU. Измерено среднее время выполнения CPU и GPU а также проверена корректность результата. GPU показал значительно меньшее время выполнения по сравнению с CPU.

#### Задание 2
Во втором задании реализована префиксная сумма массива размером 1000000 элементов. На GPU используется алгоритм Blelloch с разделяемой памятью и рекурсивная обработка сумм блоков. Также реализована последовательная версия inclusive scan на CPU. Проведено сравнение времени выполнения и максимальной абсолютной ошибки между CPU и GPU. GPU реализация оказалась быстрее.

#### Задание 3
В третьем задании реализована гибридная программа, первая половина массива обрабатывается на CPU, вторая половина массива обрабатывается на GPU. Также реализованы варианты CPU-only и GPU-only. Проведено сравнение времени выполнения всех трёх подходов и проверка корректности результатов. Показано, что GPU-only вариант является самым быстрым, а гибридный быстрее CPU-only но медленнее GPU-only.

#### Задание 4
В четвёртом задании реализована распределённая программа с использованием MPI. Массив данных размером 10000000 элементов делится между процессами с помощью MPI_Scatterv. Каждый процесс вычисляет локальную сумму после чего результаты собираются с помощью MPI_Reduce. Измерено время выполнения для 2, 4 и 8 процессов. В среде Google colab ускорение не наблюдается из-за ограниченного числа CPU ресурсов и использования режима oversubscribe, однако корректность реализации подтверждена совпадением результатов.

## Вывод
В ходе работы были реализованы параллельные вычисления на GPU с использованием CUDA, гибридные вычисления CPU+GPU и распределённые вычисления с помощью MPI. Эксперименты показали что GPU значительно быстрее CPU для обработки больших массивов данных. Использование разделяемой памяти позволяет дополнительно ускорить вычисления. Гибридный вариант работает быстрее CPU но в данной задаче уступает варианту только на GPU. MPI-реализация корректно распределяет данные между процессами однако в среде Google Colab ускорение не наблюдается из-за ограниченных ресурсов.
В результате работы получены навыки работы с CUDA и MPI и понимание особенностей гибридных и распределённых вычислений.

## Ответы на контрольные вопросы
1. В чём заключается отличие гибридных вычислений от вычислений только на CPU или только на GPU?
Гибридные вычисления используют одновременно CPU и GPU, распределяя работу между ними, а не выполняя всё на одном устройстве.

2. Для каких типов задач целесообразно распределять вычисления между CPU и GPU?
Для таких задач где часть вычислений плохо подходит для GPU (логика, ветвления), а часть хорошо параллелится (массовые операции над данными).

3. В чём разница между синхронной и асинхронной передачей данных между CPU и GPU?
Синхронная передача блокирует выполнение программы, асинхронная позволяет выполнять вычисления параллельно с копированием данных.

4. Почему асинхронная передача данных может повысить производительность программы?
Потому что позволяет перекрывать передачу данных и вычисления, уменьшая простои CPU и GPU.

5. Какие основные функции MPI используются для распределения и сбора данных между процессами?
MPI_Scatter, MPI_Scatterv, MPI_Gather, MPI_Reduce, MPI_Barrier.

6. Как количество процессов MPI влияет на время выполнения программы и почему?
При достаточных ресурсах время уменьшается, но при нехватке ресурсов и больших накладных расходах может увеличиваться.

7. Какие факторы ограничивают масштабируемость распределённых параллельных программ?
Коммуникации между процессами, задержки сети, дисбаланс нагрузки и ограниченные ресурсы.

8. В каких случаях использование распределённых вычислений оправдано, а в каких — неэффективно?
Использование распределенных вычислений оправдано для больших задач с большим объёмом вычислений и данных, неэффективно для маленьких задач где накладные расходы превышают пользу.
