## Описание работы
В практической работе №3 были реализованы три основных алгоритма сортировки: сортировка слиянием (Merge sort), быстрая сортировка (Quick sort) и пирамидальная сортировка (Heap sort). Каждый из этих алгоритмов был реализован как на центральном процессоре (CPU), так и на графическом процессоре с использованием CUDA (GPU). Основная цель проекта заключалась в том, чтобы сравнить производительность этих алгоритмов на разных устройствах и для массивов различного размера, а также увидеть, насколько ускорение на GPU зависит от объёма данных.

Сначала я реализовала алгоритмы на CPU: Merge sort рекурсивно делит массив и сливает части, Quick sort делит массив по опорному элементу, а Heap sort строит кучу и извлекает элементы. Эти версии служат эталоном для сравнения с GPU.

На GPU Merge sort делит массив на блоки, которые сортируются параллельно, после чего блоки сливаются. Quick sort и Heap sort упрощены и работают одним потоком, поэтому не используют полностью возможности CUDA, но всё равно показывают ускорение.

Программа тестирует массивы размером 10,000, 100,000 и 1,000,000 элементов. Для маленьких массивов ускорение на GPU незначительное, а для больших массивов Merge Sort и Heap Sort работают заметно быстрее CPU. Quick Sort на GPU ускоряется меньше, но выигрыш всё равно есть, особенно с ростом размера массива.

## Используемые технологии
В практической работе использованы следующие технологии:
- C++ - основной язык программирования для реализации алгоритмов.
- CUDA - для параллельной реализации сортировок на GPU.
- Библиотеки STL: vector, algorithm и другие для работы с массивами и стандартными алгоритмами.
- Random и chrono - для генерации случайных массивов и измерения времени выполнения.
  
Так как у меня нет CUDA на ноутбуке, я использовала онлайн-песочницу для CUDA leetgpu.com, чтобы протестировать и запустить код. Это позволило проверить работу алгоритмов на GPU без необходимости иметь физическую видеокарту с поддержкой CUDA.

## Выводы
Практическая работа показала, что GPU может существенно ускорять сортировку больших массивов, особенно когда алгоритм хорошо выполняется параллельно. Для маленьких массивов ускорение почти не заметно, а иногда CPU может работать даже быстрее из-за накладных расходов. Merge Sort на GPU показал лучшую масштабируемость с ростом массива, так как блоки сортируются параллельно. Quick Sort и Heap Sort на GPU в упрощённой версии тоже быстрее CPU для больших массивов, но не используют полностью параллельную мощность GPU.

В целом, практическая работа помогла понять как алгоритмы сортировки ведут себя на CPU и GPU, как важно учитывать размер данных и архитектуру параллельной обработки при оптимизации и дало полезный опыт работы с CUDA даже без полноценного GPU на ноутбуке.

## Ответы на контрольные вопросы
1. В чем различие между последовательной и параллельной реализациями
сортировки слиянием?
Последовательная сортировка делит и сливает массив шаг за шагом, а параллельная делает это сразу для нескольких частей, что ускоряет работу на больших массивах.
2. Как распределение потоков и блоков влияет на производительность на
CUDA?
Если потоков и блоков мало, GPU простаивает, если слишком много - появляются лишние накладные расходы, поэтому нужен баланс.
3. Какие сложности возникают при реализации быстрой сортировки на GPU?
Проблемы с синхронизацией потоков и доступом к памяти, плюс трудно равномерно загрузить все блоки.
4. В каких случаях параллельная реализация сортировки на GPU может быть
менее эффективной, чем на CPU?
Когда массив маленький, или когда алгоритм требует много сложной логики и ветвлений. В таких случаях управление потоками и синхронизация на GPU создаёт больше накладных расходов, чем просто последовательная работа на CPU.
5. Почему важно правильно выбирать размер блоков и потоков в CUDA?
От этого зависит, насколько эффективно будут загружены ядра GPU. Если блоки слишком маленькие то часть GPU простаивает, если слишком большие то потоки начинают конкурировать за ресурсы, и производительность падает. Правильный выбор позволяет максимально использовать мощности видеокарты.
6. Как использование разделяемой памяти может повлиять на
производительность сортировки?
Разделяемая память это память внутри блока к которой потоки обращаются быстрее чем к глобальной памяти. Если хранить там промежуточные данные при сортировке, скорость сильно растёт, потому что меньше обращений к медленной глобальной памяти.
7. Что означает принцип "разделяй и властвуй" в контексте алгоритмов
сортировки?
Это значит что массив сначала делится на части (разделяй), каждая часть сортируется отдельно а потом части объединяются (властвуй). Так сложная задача решается проще и часто быстрее, особенно если части можно обрабатывать параллельно.
