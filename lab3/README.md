## Описание работы
В практической работе №3 были реализованы три основных алгоритма сортировки: сортировка слиянием (Merge sort), быстрая сортировка (Quick sort) и пирамидальная сортировка (Heap sort). Каждый из этих алгоритмов был реализован как на центральном процессоре (CPU), так и на графическом процессоре с использованием CUDA (GPU). Основная цель проекта заключалась в том, чтобы сравнить производительность этих алгоритмов на разных устройствах и для массивов различного размера, а также увидеть, насколько ускорение на GPU зависит от объёма данных.

Сначала я реализовала алгоритмы на CPU: Merge sort рекурсивно делит массив и сливает части, Quick sort делит массив по опорному элементу, а Heap sort строит кучу и извлекает элементы. Эти версии служат эталоном для сравнения с GPU.

На GPU Merge sort делит массив на блоки, которые сортируются параллельно, после чего блоки сливаются. Quick sort и Heap sort упрощены и работают одним потоком, поэтому не используют полностью возможности CUDA, но всё равно показывают ускорение.

Программа тестирует массивы размером 10,000, 100,000 и 1,000,000 элементов. Для маленьких массивов ускорение на GPU незначительное, а для больших массивов Merge Sort и Heap Sort работают заметно быстрее CPU. Quick Sort на GPU ускоряется меньше, но выигрыш всё равно есть, особенно с ростом размера массива.

## Используемые технологии
В практической работе использованы следующие технологии:
- C++ - основной язык программирования для реализации алгоритмов.
- CUDA - для параллельной реализации сортировок на GPU.
- Библиотеки STL: vector, algorithm и другие для работы с массивами и стандартными алгоритмами.
- Random и chrono - для генерации случайных массивов и измерения времени выполнения.
  
Так как у меня нет CUDA на ноутбуке, я использовала онлайн-песочницу для CUDA leetgpu.com, чтобы протестировать и запустить код. Это позволило проверить работу алгоритмов на GPU без необходимости иметь физическую видеокарту с поддержкой CUDA.

## Выводы
Практическая работа показала, что GPU может существенно ускорять сортировку больших массивов, особенно когда алгоритм хорошо выполняется параллельно. Для маленьких массивов ускорение почти не заметно, а иногда CPU может работать даже быстрее из-за накладных расходов. Merge Sort на GPU показал лучшую масштабируемость с ростом массива, так как блоки сортируются параллельно. Quick Sort и Heap Sort на GPU в упрощённой версии тоже быстрее CPU для больших массивов, но не используют полностью параллельную мощность GPU.

В целом, практическая работа помогла понять как алгоритмы сортировки ведут себя на CPU и GPU, как важно учитывать размер данных и архитектуру параллельной обработки при оптимизации и дало полезный опыт работы с CUDA даже без полноценного GPU на ноутбуке.
